{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-08T15:36:29.939152Z","iopub.execute_input":"2021-11-08T15:36:29.939782Z","iopub.status.idle":"2021-11-08T15:36:29.970424Z","shell.execute_reply.started":"2021-11-08T15:36:29.939687Z","shell.execute_reply":"2021-11-08T15:36:29.969298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing necessary libraries and hard-coded values\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport os\n\nimport keras\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\nfrom tensorflow.keras import Input\n\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\n\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\n\nIMAGE_SIZE = [224,224]\nEPOCHS = 25\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:29.980979Z","iopub.execute_input":"2021-11-08T15:36:29.981669Z","iopub.status.idle":"2021-11-08T15:36:35.379311Z","shell.execute_reply.started":"2021-11-08T15:36:29.98163Z","shell.execute_reply":"2021-11-08T15:36:35.378561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting filenames from our dataset \nfilenames = tf.io.gfile.glob('../input/chest-xray-pneumonia/chest_xray/train/*/*')\nfilenames.extend(tf.io.gfile.glob('../input/chest-xray-pneumonia/chest_xray/val/*/*'))\n\n\ntrain_filenames, val_filenames = train_test_split(filenames, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:35.382778Z","iopub.execute_input":"2021-11-08T15:36:35.383276Z","iopub.status.idle":"2021-11-08T15:36:36.591322Z","shell.execute_reply.started":"2021-11-08T15:36:35.383218Z","shell.execute_reply":"2021-11-08T15:36:36.590549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(filenames))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-08T15:36:36.592745Z","iopub.execute_input":"2021-11-08T15:36:36.593265Z","iopub.status.idle":"2021-11-08T15:36:36.599153Z","shell.execute_reply.started":"2021-11-08T15:36:36.593211Z","shell.execute_reply":"2021-11-08T15:36:36.598482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:36.600539Z","iopub.execute_input":"2021-11-08T15:36:36.601051Z","iopub.status.idle":"2021-11-08T15:36:38.872497Z","shell.execute_reply.started":"2021-11-08T15:36:36.600997Z","shell.execute_reply":"2021-11-08T15:36:38.87175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index,element in enumerate(val_list_ds):\n    print(element)\n    if index == 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:38.874907Z","iopub.execute_input":"2021-11-08T15:36:38.875343Z","iopub.status.idle":"2021-11-08T15:36:38.911597Z","shell.execute_reply.started":"2021-11-08T15:36:38.875305Z","shell.execute_reply":"2021-11-08T15:36:38.910787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))\n\nTRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:38.912738Z","iopub.execute_input":"2021-11-08T15:36:38.913552Z","iopub.status.idle":"2021-11-08T15:36:38.924083Z","shell.execute_reply.started":"2021-11-08T15:36:38.913513Z","shell.execute_reply":"2021-11-08T15:36:38.923273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(\"../input/chest-xray-pneumonia/chest_xray/train/*\")])\nCLASS_NAMES","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:38.926343Z","iopub.execute_input":"2021-11-08T15:36:38.926628Z","iopub.status.idle":"2021-11-08T15:36:39.004766Z","shell.execute_reply.started":"2021-11-08T15:36:38.926591Z","shell.execute_reply":"2021-11-08T15:36:39.004112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# What we want to do is map each filename to the corresponding pair - image,label. What we can do is rewrite\n# labels as 1 indicating pneumonia and 0 indicating normal diagnose.\ndef get_label(file_path):\n    # convert the path to a list of path components     \n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == \"PNEUMONIA\"","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.006203Z","iopub.execute_input":"2021-11-08T15:36:39.00654Z","iopub.status.idle":"2021-11-08T15:36:39.011681Z","shell.execute_reply.started":"2021-11-08T15:36:39.006501Z","shell.execute_reply":"2021-11-08T15:36:39.010707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_img(img):\n    # Decode a jpeg image to a unit8 tensor, channels indicate RGB\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Converting integer types to floating point types returns normalized floating point values in the range [0,1)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # Resize and return the image to the pre hard-coded resolution \n    return tf.image.resize(img, IMAGE_SIZE)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.013596Z","iopub.execute_input":"2021-11-08T15:36:39.013925Z","iopub.status.idle":"2021-11-08T15:36:39.021228Z","shell.execute_reply.started":"2021-11-08T15:36:39.013853Z","shell.execute_reply":"2021-11-08T15:36:39.020432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_path(file_path):\n    # Getting label for a desired path     \n    label = get_label(file_path)\n    # Loading raw image and processing into desired range.\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.023123Z","iopub.execute_input":"2021-11-08T15:36:39.023438Z","iopub.status.idle":"2021-11-08T15:36:39.032187Z","shell.execute_reply.started":"2021-11-08T15:36:39.023404Z","shell.execute_reply":"2021-11-08T15:36:39.031413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we have to map corresponding pairs in a train and val dataset\ntrain_ds = train_list_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\nval_ds = val_list_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.03333Z","iopub.execute_input":"2021-11-08T15:36:39.033608Z","iopub.status.idle":"2021-11-08T15:36:39.402944Z","shell.execute_reply.started":"2021-11-08T15:36:39.033567Z","shell.execute_reply":"2021-11-08T15:36:39.402273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint(train_ds)\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy())\n    print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.404191Z","iopub.execute_input":"2021-11-08T15:36:39.40445Z","iopub.status.idle":"2021-11-08T15:36:39.545004Z","shell.execute_reply.started":"2021-11-08T15:36:39.404417Z","shell.execute_reply":"2021-11-08T15:36:39.54418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing the test dataset\ntest_list_ds = tf.data.Dataset.list_files(str('../input/chest-xray-pneumonia/chest_xray/test/*/*'))\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\ntest_ds = test_list_ds.map(process_path, num_parallel_calls = tf.data.AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\nTEST_IMAGE_COUNT","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.546292Z","iopub.execute_input":"2021-11-08T15:36:39.54658Z","iopub.status.idle":"2021-11-08T15:36:39.649824Z","shell.execute_reply.started":"2021-11-08T15:36:39.54653Z","shell.execute_reply":"2021-11-08T15:36:39.649145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the dataset","metadata":{}},{"cell_type":"code","source":"# We'll use buffered prefetching so we can yield data from disk\ndef prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    \n    # Randomly shuffles a tensor along its first dimension.     \n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    \n    # Repeat forever\n    ds = ds.repeat()\n    \n    # Combines consecutive elementes of this dataset into batches. N(batches) = len(ds) / batch_size \n    ds = ds.batch(BATCH_SIZE)\n    \n    # 'prefetch' lets the dataset fetch batches in the background while the model is training \n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    \n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.653131Z","iopub.execute_input":"2021-11-08T15:36:39.653475Z","iopub.status.idle":"2021-11-08T15:36:39.660889Z","shell.execute_reply.started":"2021-11-08T15:36:39.653443Z","shell.execute_reply":"2021-11-08T15:36:39.659933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the next batch iteration of the training data\ntrain_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch,label_batch = next(iter(train_ds))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:39.662098Z","iopub.execute_input":"2021-11-08T15:36:39.662699Z","iopub.status.idle":"2021-11-08T15:36:54.476074Z","shell.execute_reply.started":"2021-11-08T15:36:39.662631Z","shell.execute_reply":"2021-11-08T15:36:54.474157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(image_batch, label_batch):\n#     plt.figure(figsize=(30,10))\n    f, ax = plt.subplots(3,5, figsize=(30,10))\n    for n in range(15):\n        ax[n//5, n%5].imshow(image_batch[n], cmap = 'gray')\n        if label_batch[n]:\n            ax[n//5, n%5].set_title(\"PNEUMONIA\")\n        else:\n            ax[n//5, n%5].set_title(\"NORMAL\")\n        ax[n//5, n%5].axis('off')\n#         ax[n//5, n%5].set_aspect('auto')","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:54.483892Z","iopub.execute_input":"2021-11-08T15:36:54.484119Z","iopub.status.idle":"2021-11-08T15:36:54.495566Z","shell.execute_reply.started":"2021-11-08T15:36:54.484092Z","shell.execute_reply":"2021-11-08T15:36:54.493869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(image_batch.numpy(), label_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:54.496851Z","iopub.execute_input":"2021-11-08T15:36:54.497579Z","iopub.status.idle":"2021-11-08T15:36:55.873709Z","shell.execute_reply.started":"2021-11-08T15:36:54.497539Z","shell.execute_reply":"2021-11-08T15:36:55.871307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading and Base Model Training","metadata":{}},{"cell_type":"code","source":"# VGG16 \n\nbase_model = tf.keras.applications.VGG16(\n    input_shape = (IMAGE_SIZE[0], IMAGE_SIZE[0], 3),\n    weights = 'imagenet',\n    include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = layers.Flatten()(base_model.output)\nx = layers.Dense(512, activation='relu')(x)\n# x = layers.Dropout(0.05)(x)\noutput = layers.Dense(len(CLASS_NAMES)-1, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:55.874796Z","iopub.execute_input":"2021-11-08T15:36:55.875042Z","iopub.status.idle":"2021-11-08T15:36:56.563039Z","shell.execute_reply.started":"2021-11-08T15:36:55.875008Z","shell.execute_reply":"2021-11-08T15:36:56.56229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.575214Z","iopub.execute_input":"2021-11-08T15:36:56.575546Z","iopub.status.idle":"2021-11-08T15:36:56.596996Z","shell.execute_reply.started":"2021-11-08T15:36:56.575517Z","shell.execute_reply":"2021-11-08T15:36:56.596295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = tf.keras.applications.EfficientNetB5(\n#     include_top=False,\n#     weights='imagenet',\n#     input_shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n# )\n\n# base_model.trainable = True\n\n# inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n# x = base_model(inputs)\n# x = layers.GlobalAveragePooling2D()(x)\n# x = layers.Dropout(0.25)(x)\n# output = layers.Dense(1, activation='sigmoid')(x)\n\n# model = Model(inputs, output)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.5983Z","iopub.execute_input":"2021-11-08T15:36:56.598537Z","iopub.status.idle":"2021-11-08T15:36:56.602295Z","shell.execute_reply.started":"2021-11-08T15:36:56.598505Z","shell.execute_reply":"2021-11-08T15:36:56.601548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correct for data imbalance","metadata":{}},{"cell_type":"code","source":"# Taking the natural logarithm of COUNT_PNEUMONIA and COUNT_NORMAL dividend. \ninitial_bias = np.log([COUNT_PNEUMONIA/COUNT_NORMAL])\nprint(\"Pneumonia: %i , Normal: %i, Initial_bias: %f \" %(COUNT_PNEUMONIA, COUNT_NORMAL, initial_bias))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.603445Z","iopub.execute_input":"2021-11-08T15:36:56.603692Z","iopub.status.idle":"2021-11-08T15:36:56.614637Z","shell.execute_reply.started":"2021-11-08T15:36:56.603661Z","shell.execute_reply":"2021-11-08T15:36:56.613916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# w0 = (4185/1086)/2 = 1.92\n# w1 = (4185/3099)/2 = 0.67\nweight_for_0 = (1 / COUNT_NORMAL) * (TRAIN_IMG_COUNT) / 2.0\nweight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0 \n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.615927Z","iopub.execute_input":"2021-11-08T15:36:56.6163Z","iopub.status.idle":"2021-11-08T15:36:56.625295Z","shell.execute_reply.started":"2021-11-08T15:36:56.616264Z","shell.execute_reply":"2021-11-08T15:36:56.624302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","metadata":{}},{"cell_type":"code","source":"optAdam = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nwith strategy.scope():\n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n    \n    model.compile(\n        optimizer= optAdam,\n        loss= 'binary_crossentropy',\n        metrics= ['accuracy']\n    )","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.626702Z","iopub.execute_input":"2021-11-08T15:36:56.627068Z","iopub.status.idle":"2021-11-08T15:36:56.648471Z","shell.execute_reply.started":"2021-11-08T15:36:56.627028Z","shell.execute_reply":"2021-11-08T15:36:56.647796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finetune the model","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfilepath = 'best_model.h5'\n\nearly_stopping_cb = EarlyStopping(patience=5,\n                                monitor='val_loss',\n                                mode='min',\n                                verbose=1)\n\nModelCheckpoint = ModelCheckpoint(filepath,\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=2.5e-5)\n\ncallbacks_list = [ModelCheckpoint, early_stopping_cb, learning_rate_reduction]","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.649607Z","iopub.execute_input":"2021-11-08T15:36:56.650173Z","iopub.status.idle":"2021-11-08T15:36:56.657203Z","shell.execute_reply.started":"2021-11-08T15:36:56.650135Z","shell.execute_reply":"2021-11-08T15:36:56.656416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_epochs = 35\n\nhistory = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n    epochs= no_epochs,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n    class_weight=class_weight,\n    callbacks=callbacks_list\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:36:56.658613Z","iopub.execute_input":"2021-11-08T15:36:56.659134Z","iopub.status.idle":"2021-11-08T15:40:12.052615Z","shell.execute_reply.started":"2021-11-08T15:36:56.659096Z","shell.execute_reply":"2021-11-08T15:40:12.05191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(10)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='accuracy')\nplt.plot(epochs_range, val_acc, label='val_accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:43:35.043938Z","iopub.execute_input":"2021-11-08T15:43:35.0442Z","iopub.status.idle":"2021-11-08T15:43:35.269931Z","shell.execute_reply.started":"2021-11-08T15:43:35.04417Z","shell.execute_reply":"2021-11-08T15:43:35.268942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(\n#     train_ds,\n#     steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n#     epochs=100,\n#     validation_data=val_ds,\n#     validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n#     class_weight=class_weight,\n#     callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler]\n# )","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:40:12.548101Z","iopub.status.idle":"2021-11-08T15:40:12.549117Z","shell.execute_reply.started":"2021-11-08T15:40:12.548868Z","shell.execute_reply":"2021-11-08T15:40:12.548893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\nloaded_model = load_model('./best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:43:39.27697Z","iopub.execute_input":"2021-11-08T15:43:39.277527Z","iopub.status.idle":"2021-11-08T15:43:39.776005Z","shell.execute_reply.started":"2021-11-08T15:43:39.277488Z","shell.execute_reply":"2021-11-08T15:43:39.775232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing model performance","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,4, figsize=(20,3))\nax = ax.ravel()\n\nfor i, met in enumerate([ 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:43:56.686769Z","iopub.execute_input":"2021-11-08T15:43:56.687039Z","iopub.status.idle":"2021-11-08T15:43:57.483981Z","shell.execute_reply.started":"2021-11-08T15:43:56.687009Z","shell.execute_reply":"2021-11-08T15:43:57.483302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict and evautae results","metadata":{}},{"cell_type":"code","source":"loss, acc, prec, rec = loaded_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T15:40:12.554154Z","iopub.status.idle":"2021-11-08T15:40:12.554874Z","shell.execute_reply.started":"2021-11-08T15:40:12.554622Z","shell.execute_reply":"2021-11-08T15:40:12.554645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}